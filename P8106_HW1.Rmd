---
title: "P8106_HW1"
author: "Ziyi Zhao"
date: "2/24/2020"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(summarytools)
library(stargazer)
library(leaps)
library(caret)
library(FNN)
library(ModelMetrics)
library(Rcpp)
library(microbenchmark)
library(glmnet)
library(corrplot)
library(plotmo)
library(pls)

```


# Part a: Fit a linear model using least squares on the training data and calculate the mean square error using the test data.

We first look at the summary statistics of predictors and the response.

```{r}
sol_train = read_csv("./solubility_train.csv") %>% janitor::clean_names()
sol_test = read_csv("./solubility_test.csv") %>% janitor::clean_names()

st_options(plain.ascii = FALSE,
           style = "rmarkdown",
           dfSummary.silent = TRUE,
           footnote = NA,
           subtitle.emphasis = FALSE)

dfSummary(sol_train[,-229])
dfSummary(sol_test[,-229])

sol_all <- rbind(sol_train,sol_test)
dfSummary(sol_all[,-229])

```

Creat a correlation plot on total datasets (training + test) to see how predictors are correlated

```{r fig.width=25,fig.height=25}
predictor_mtx <- model.matrix(solubility~.,sol_all)[,-1]
predictor_mtx_test <- model.matrix(solubility~.,sol_test)[,-1]

response_vtr <- sol_all$solubility

ctrl1 <- trainControl(method = "repeatedcv",number = 10,repeats = 5)

corrplot(cor(predictor_mtx))

```

From the correlation plot, we can observe that there are some positively correlated predictors, shown as dark-blue dots in the plot.

We fit linear least square model to train dataset and calculate MSE using test dataset.

We also compute KNN from k=2 to k=20.

```{r}
linear_fit <- lm(solubility~.,data=sol_train)

linear_pred <- predict(linear_fit,sol_test)

mse(sol_test$solubility,linear_pred)

# KNN
mse_knn <- rep(0,19)
for (i in 2:20) {
  pred_knn <- knn.reg(train = sol_train[,1:228], test = sol_test[,1:228],
                     y = sol_train$solubility,k=i)
  mse_knn[i-1] <- mse(sol_test$solubility,pred_knn$pred)
}

min(mse_knn)

knn_k <- c(2:20)
tibble(knn_k,mse_knn) %>% 
  ggplot(aes(x=knn_k,y=mse_knn))+
  geom_point()+
  labs(title = "MSE change by different k",
       x = "k",
       y = "mse")


```

The mean squared error of fitting linear model is `r mse(sol_test$solubility,linear_pred)`.

Use Caret to fit linear model to see the change of mean squared error.

```{r}
set.seed(7)
lm.fit <- train(predictor_mtx,response_vtr,
                method = "lm",
                trControl = ctrl1)

pred.lm <- predict(lm.fit$finalModel,
                   newdata = data.frame(predictor_mtx_test))

mse(sol_test$solubility,pred.lm)

(lm.info <- postResample(predict(lm.fit,predictor_mtx_test),
                         sol_test$solubility))
```

The mean squared error by fitting linear error using caret is `r mse(sol_test$solubility,pred.lm)`.

The purpose of using caret is to help discussion of four model.

# Part b: Fit a ridge regression model on the training data, with λ chosen by cross-validation. Report the test error

Let's fit a ridge regression model on the training data, with lambda chosen by cross-validation

```{r fig.height=20,fig.width=25}
predictor_mtx <- model.matrix(solubility~.,sol_train)[,-1]
response_vtr <- sol_train$solubility

ridge.mod <- glmnet(predictor_mtx,response_vtr,standardize = TRUE,
                    alpha = 0,
                    lambda = exp(seq(-5,8,length=100)))
mat.coef <- coef(ridge.mod)
dim(mat.coef)

# trace plot
plot_glmnet(ridge.mod,xvar = "rlambda",label = 228)

```

The trace plot show how coefficients change as log lambda decreases.

Use cross validation to determine the optimal value of lambda. Then, use the best lambda to fit the ridge regression to test dataset and get MSE.

```{r}
set.seed(7)
cv.ridge <- cv.glmnet(predictor_mtx,response_vtr,type.measure = "mse",
                      alpha=0,lambda = exp(seq(-5,1,length=100)))
plot(cv.ridge)

best.lambda <- cv.ridge$lambda.1se
best.lambda

# coefficients of the final model
predict(ridge.mod,s=best.lambda,type = "coefficients")

ridge_pred <- predict(ridge.mod,s=best.lambda,newx = predictor_mtx_test)
mse(sol_test$solubility,ridge_pred[,1])


```

The optimal lambda acquired from cross-validation is `r best.lambda`.

The mean squared error we got is `r mse(sol_test$solubility,ridge_pred[,1])`.

Use caret to re-do ridge to see change of MSE.

```{r}
set.seed(7)
ridge.fit <- train(predictor_mtx,response_vtr,
                   method = "glmnet",
                   tuneGrid = expand.grid(alpha=0,
                                        lambda=exp(seq(-5,1,length=100))),
                   trControl = ctrl1)

plot(ridge.fit,xTrans = function(predictor_mtx)log(predictor_mtx))

ridge.fit$bestTune
coef(ridge.fit$finalModel,ridge.fit$bestTune$lambda)

pred.ridge <- predict(ridge.fit,s=ridge.fit$bestTune$lambda,
                      newdata = predictor_mtx_test)

mse(sol_test$solubility,pred.ridge)

(ridge_info <- postResample(predict(ridge.fit,predictor_mtx_test),
                           sol_test$solubility))

```

The mean square error of fitting ridge using carot is `r mse(sol_test$solubility,pred.ridge)`.

# Fit a lasso model on the training data, with λ chosen by cross-validation. Report the test error, along with the number of non-zero coefficient estimates.

```{r}
set.seed(7)
cv.lasso <- cv.glmnet(predictor_mtx,response_vtr,alpha=1,
                      lambda = exp(seq(-10,-1,length=100)))
plot(cv.lasso)

# trace plot
plot_glmnet(cv.lasso$glmnet.fit)

# coefficients of final model
predict(cv.lasso,s="lambda.1se",type="coefficients")

lasso_pred <- predict(cv.lasso,s="lambda.1se",newx = predictor_mtx_test)
mse(sol_test$solubility,lasso_pred[,1])

```

The mean squared error is `r mse(sol_test$solubility,lasso_pred[,1])`.

We use caret to redo lasso to see change of MSE.

```{r}
set.seed(7)
lasso.fit <- train(predictor_mtx,response_vtr,
                   method="glmnet",
                   tuneGrid = expand.grid(alpha=1,
                                          lambda=exp(seq(-10,1,length=100))),
                   trControl = ctrl1)
plot(lasso.fit,xTrans = function(predictor_mtx)log(predictor_mtx))

lasso.fit$bestTune
coef(lasso.fit$finalModel,lasso.fit$bestTune$lambda)

pred.lasso <- predict(lasso.fit,s=lasso.fit$bestTune$lambda,
                      newdata = predictor_mtx_test)

mse(sol_test$solubility,pred.lasso)

(lasso.info <- postResample(predict(lasso.fit,predictor_mtx_test),
                            sol_test$solubility))

```

The mean square error of fitting lasso using caret is `r mse(sol_test$solubility,pred.lasso)`.

# Fit a principle component regression model on the training data, with M chosen by cross-validation. Report the test error, along with the value of M selected by cross-validation.

```{r}
set.seed(7)
pcr.mod <- pcr(solubility~.,
               data=sol_train,
               scale=TRUE,
               validation="CV") 
summary(pcr.mod)

validationplot(pcr.mod,val.type = "MSEP",legendpos="topright")

cv.mse <- RMSEP(pcr.mod)
ncomp.cv <- which.min(cv.mse$val[1,,])-1
ncomp.cv

pcr_pred <- predict(pcr.mod,newdata = predictor_mtx_test,
                    ncomp = ncomp.cv)
mse(sol_test$solubility,pcr_pred)

```

The mean square error of fitting PCR is `r mse(sol_test$solubility,pcr_pred)`.

The M is `r ncomp.cv`.

```{r}
set.seed(7)
pcr.fit <- train(predictor_mtx,response_vtr,
                 method = "pcr",
                 tuneGrid = data.frame(ncomp=1:228),
                 trControl = ctrl1,
                 preProc=c("center","scale"))

trans <- preProcess(predictor_mtx,method = c("center","scale"))
pred.pcr <- predict(pcr.fit$finalModel,newdata = predict(trans,predictor_mtx_test),
                    ncomp = pcr.fit$bestTune$ncomp)

mse(sol_test$solubility,pred.pcr)

(pcr.info <- postResample(predict(pcr.fit,predictor_mtx_test),
                          sol_test$solubility))

```

The mean square error of fitting PCR using caret is `r mse(sol_test$solubility,pred.pcr)`.

The M is `r pcr.fit$bestTune$ncomp`.

# Brieﬂy discuss the results obtained in (a)∼(d).

```{r}
resamp <- resamples(list(lm = lm.fit,
                         ridge = ridge.fit,
                         lasso = lasso.fit,
                         pcr = pcr.fit))
summary(resamp)

```

Create boxplot of RMSE for four regression models.

```{r}
bwplot(resamp,metric = "RMSE")
```



* The MSE of fitting linear model to test dataset is `r mse(sol_test$solubility,linear_pred)`.The MSE by fitting linear error using caret is `r mse(sol_test$solubility,pred.lm)`.

* The MSE of fitting ridge model to test dataset is `r mse(sol_test$solubility,ridge_pred[,1])`. MSE using Caret is `r mse(sol_test$solubility,pred.ridge)`.

* The MSE of fitting lasso model to test dataset is `r mse(sol_test$solubility,lasso_pred[,1])`. MSE using Caret is `r mse(sol_test$solubility,pred.lasso)`.

* The MSE of fitting PCR to test dataset is `r mse(sol_test$solubility,pcr_pred)`. MSE using Caret is `r mse(sol_test$solubility,pred.pcr)`.

I used same method of cross validation. Using the caret, model of lasso regression has the smallest mean squared error. Through the output of resample function, lasso regression has smallest mean of RMSE and MAE. We can also find out this point from the boxplot. The lasso also have greatest mean of Rsquared value, which means how much percent of solubility were explained by the predictors.

# Which model will you choose for predicting solubility?
I will choose lasso regression to predict solubility, because it has the smallest MSE when fitting the test dataset. It also has smallest meanof RMSE and MAE values, and largest Rsquared value. 








